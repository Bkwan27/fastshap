{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cordless-screen",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heard-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "serial-impression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load train set\n",
    "train_set = dsets.CIFAR10('../', train=True, download=True, transform=transform_train)\n",
    "\n",
    "# Load test set (using as validation)\n",
    "val_set = dsets.CIFAR10('../', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753ce60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\bryan\\\\fastshap\\\\notebooks', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\python310.zip', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\DLLs', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\Users\\\\bryan\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0', '', 'C:\\\\Users\\\\bryan\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages', 'C:\\\\Users\\\\bryan\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages\\\\win32', 'C:\\\\Users\\\\bryan\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\bryan\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages\\\\Pythonwin', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\\\lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('c:/Users/bryan/fastshap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-praise",
   "metadata": {},
   "source": [
    "# Train model with missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stainless-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os.path\n",
    "from resnet import ResNet18\n",
    "from fastshap import ImageSurrogate\n",
    "from fastshap.utils import MaskLayer2d, KLDivLoss, DatasetInputOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "figured-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indoor-surname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model\n"
     ]
    }
   ],
   "source": [
    "# Check for model\n",
    "if os.path.isfile('cifar missingness.pt'):\n",
    "    print('Loading saved model')\n",
    "    model = torch.load('cifar missingness.pt').to(device)\n",
    "    imputer = ImageSurrogate(model, width=32, height=32, superpixel_size=2)\n",
    "\n",
    "else:\n",
    "    # Create model\n",
    "    model = nn.Sequential(\n",
    "        MaskLayer2d(value=0, append=True),\n",
    "        ResNet18(in_channels=4, num_classes=10)).to(device)\n",
    "    \n",
    "    # familiariaze with DataLoader\n",
    "    # Set up surrogate wrapper (although this is not a surrogate model)\n",
    "    imputer = ImageSurrogate(model, width=32, height=32, superpixel_size=2)\n",
    "\n",
    "    # Train\n",
    "    imputer.train(train_set,\n",
    "                  val_set,\n",
    "                  batch_size=256,\n",
    "                  max_epochs=100,\n",
    "                  loss_fn=nn.CrossEntropyLoss(),\n",
    "                  lookback=10,\n",
    "                  bar=True,\n",
    "                  verbose=True)\n",
    "    \n",
    "    # Save model\n",
    "    model.cpu()\n",
    "    torch.save(model, 'cifar missingness.pt')\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-oklahoma",
   "metadata": {},
   "source": [
    "# Train FastSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prerequisite-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet\n",
    "from fastshap import FastSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ff4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "average-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explainer model\n"
     ]
    }
   ],
   "source": [
    "# Check for model\n",
    "if os.path.isfile('cifar missingness explainer.pt'):\n",
    "    print('Loading saved explainer model')\n",
    "    explainer = torch.load('cifar missingness explainer.pt').to(device)\n",
    "    fastshap = FastSHAP(explainer, imputer, link=nn.LogSoftmax(dim=1))\n",
    "\n",
    "else:\n",
    "    # Set up explainer model\n",
    "    explainer = UNet(n_classes=10, num_down=2, num_up=1, num_convs=3).to(device)\n",
    "\n",
    "    # Set up FastSHAP object\n",
    "    fastshap = FastSHAP(explainer, imputer, link=nn.LogSoftmax(dim=1))\n",
    "\n",
    "    # Set up datasets\n",
    "    # the train and val set are just the CIFAR dataset\n",
    "    fastshap_train = DatasetInputOnly(train_set)\n",
    "    fastshap_val = DatasetInputOnly(val_set)\n",
    "\n",
    "    # Train\n",
    "    fastshap.train(\n",
    "        fastshap_train,\n",
    "        fastshap_val,\n",
    "        batch_size=128,\n",
    "        num_samples=2,\n",
    "        max_epochs=200,\n",
    "        eff_lambda=1e-2,\n",
    "        validation_samples=1,\n",
    "        lookback=10,\n",
    "        bar=True,\n",
    "        verbose=True)\n",
    "    \n",
    "    # Save explainer\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, 'cifar missingness explainer.pt')\n",
    "    explainer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-dimension",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "desirable-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "44aa4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_exclusion(values, samples, targets):\n",
    "    inclusion_auc = []\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        # Sort SHAP values for each instance\n",
    "        print(i)\n",
    "        sorted_val = torch.sort(values[i, targets[i]].flatten(), descending=True)[0]\n",
    "        #print(sorted_val)\n",
    "        \n",
    "        # Compute inclusion percentage thresholds\n",
    "        inclusion_percentages = torch.linspace(0, 1, len(sorted_val) + 1)\n",
    "        #print(inclusion_percentages)\n",
    "        \n",
    "        top1_accuracies = []\n",
    "        # Iterate over inclusion percentage thresholds\n",
    "\n",
    "        for threshold in inclusion_percentages:\n",
    "            # Create binary mask for the top features\n",
    "            mask = values[i, targets[i]] >= sorted_val[int(threshold * (len(sorted_val)-1))]\n",
    "            mask = mask.reshape(-1)\n",
    "            mask = mask.view((1, 256))\n",
    "            #print(mask.shape)\n",
    "            \n",
    "            # Upsample binary mask if necessary\n",
    "            #mask = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), (32, 32), mode='nearest').bool()\n",
    "            \n",
    "            # Apply mask to input image\n",
    "            # masked_image = x.clone()[i]\n",
    "            # masked_image[:, mask[0][0]] = 100  # Example modification\n",
    "            \n",
    "            # Downsample masked image (if needed) and perform inference\n",
    "            #downsampled_image = F.interpolate(masked_image, (16, 16), mode='bilinear', align_corners=False)\n",
    "            S = torch.ones(1, imputer.num_players, device=device)\n",
    "            S[mask] = 0\n",
    "            #print(S)\n",
    "            output = imputer(samples[i].to(device), S).softmax(dim=1).cpu().data\n",
    "            \n",
    "            # Compute top-1 accuracy\n",
    "            _, predicted = torch.max(output, dim=1)\n",
    "            #print(predicted)\n",
    "            correct = (predicted == targets[i]).sum().item()\n",
    "            accuracy = correct\n",
    "            \n",
    "            top1_accuracies.append(accuracy)\n",
    "        \n",
    "        # Compute AUC for inclusion percentages vs. top-1 accuracies curve\n",
    "        top1_accuracies=torch.tensor(top1_accuracies)\n",
    "        auc = torch.trapz(top1_accuracies, inclusion_percentages)\n",
    "        inclusion_auc.append(auc)\n",
    "\n",
    "    # Compute average inclusion AUC across all instances\n",
    "    average_auc = torch.mean(torch.tensor(inclusion_auc))\n",
    "    #print(inclusion_auc)\n",
    "    print(\"Average exclusion AUC:\", average_auc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c2255e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inclusion(values, samples, targets):\n",
    "    inclusion_auc = []\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        # Sort SHAP values for each instance\n",
    "        print(i)\n",
    "        sorted_val = torch.sort(values[i, targets[i]].flatten(), descending=True)[0]\n",
    "        #print(sorted_val)\n",
    "        \n",
    "        # Compute inclusion percentage thresholds\n",
    "        inclusion_percentages = torch.linspace(0, 1, len(sorted_val) + 1)\n",
    "        #print(inclusion_percentages)\n",
    "        \n",
    "        top1_accuracies = []\n",
    "        # Iterate over inclusion percentage thresholds\n",
    "\n",
    "        for threshold in inclusion_percentages:\n",
    "            # Create binary mask for the top features\n",
    "            # what I changed for exclusion is that there is a < instead of a >=\n",
    "            mask = values[i, targets[i]] < sorted_val[int(threshold * (len(sorted_val)-1))]\n",
    "            mask = mask.reshape(-1)\n",
    "            mask = mask.view((1, 256))\n",
    "            #print(mask.shape)\n",
    "            \n",
    "            # Upsample binary mask if necessary\n",
    "            #mask = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), (32, 32), mode='nearest').bool()\n",
    "            \n",
    "            # Apply mask to input image\n",
    "            # masked_image = x.clone()[i]\n",
    "            # masked_image[:, mask[0][0]] = 100  # Example modification\n",
    "            \n",
    "            # Downsample masked image (if needed) and perform inference\n",
    "            #downsampled_image = F.interpolate(masked_image, (16, 16), mode='bilinear', align_corners=False)\n",
    "            S = torch.ones(1, imputer.num_players, device=device)\n",
    "            S[mask] = 0\n",
    "            #print(S)\n",
    "            output = imputer(samples[i].to(device), S).softmax(dim=1).cpu().data\n",
    "            \n",
    "            # Compute top-1 accuracy\n",
    "            _, predicted = torch.max(output, dim=1)\n",
    "            #print(predicted)\n",
    "            correct = (predicted == targets[i]).sum().item()\n",
    "            accuracy = correct\n",
    "            \n",
    "            top1_accuracies.append(accuracy)\n",
    "        \n",
    "        # Compute AUC for inclusion percentages vs. top-1 accuracies curve\n",
    "        top1_accuracies=torch.tensor(top1_accuracies)\n",
    "        auc = torch.trapz(top1_accuracies, inclusion_percentages)\n",
    "        inclusion_auc.append(auc)\n",
    "\n",
    "    # Compute average inclusion AUC across all instances\n",
    "    average_auc = torch.mean(torch.tensor(inclusion_auc))\n",
    "    #print(inclusion_auc)\n",
    "    print(\"Average inclusion AUC:\", average_auc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "juvenile-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of SHAP values tensor: torch.Size([10000, 10, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# Select one image from each class\n",
    "dset = val_set\n",
    "samples = np.array(dset.data)\n",
    "targets = np.array(dset.targets)\n",
    "num_classes = targets.max() + 1\n",
    "inds_lists = [np.where(targets == cat)[0] for cat in range(num_classes)]\n",
    "inds = [np.random.choice(cat_inds) for cat_inds in inds_lists]\n",
    "x, y = zip(*list(dset))\n",
    "x = torch.stack(x)\n",
    "\n",
    "# # Get explanations\n",
    "# values = torch.tensor(fastshap.shap_values(x.to(device)))\n",
    "# print(values.shape)\n",
    "# sorted_val = []\n",
    "# sorted_masks = []\n",
    "# for i in range(len(values)):\n",
    "#     sorted_val.append(values[i][i].flatten())\n",
    "#     sorted_val[i] = sorted(sorted_val[i], reverse=True)\n",
    "#     temp_coord = []\n",
    "#     for j in range(len(sorted_val[i])):\n",
    "#         mask = (values[i][i] == sorted_val[i][j])\n",
    "#         #print(mask)\n",
    "#         temp_coord.append(mask)\n",
    "#     sorted_masks.append(temp_coord)\n",
    "#     print(len(sorted_val))\n",
    "\n",
    "# eval_x = x\n",
    "# print(eval_x.shape)\n",
    "# top1_accuracies = []\n",
    "# for i in range(len(sorted_val[i])):\n",
    "#     for j in range(len(sorted_val)):\n",
    "#         mask = sorted_masks[j][0]\n",
    "#         print(mask)\n",
    "#         downsampled_tensor = F.interpolate(eval_x, (16, 16), mode='bilinear', align_corners=False)\n",
    "#         downsampled_tensor[j,:,mask] = 100\n",
    "#         eval_x = F.interpolate(downsampled_tensor, (32, 32), mode='bilinear', align_corners=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming values is your SHAP values tensor with shape (batch_size, num_classes, num_features, height, width)\n",
    "#values = torch.tensor(fastshap.shap_values(x.to(device)))\n",
    "values_val = torch.tensor(fastshap.shap_values(x.to(device)))\n",
    "print(\"Shape of SHAP values tensor:\", values_val.shape)\n",
    "\n",
    "calculate_exclusion(values_val, x, y)\n",
    "calculate_inclusion(values_val, x, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# basically get the classification accuracy of the imputer model whenever as you remove the top included pixel features and map this\n",
    "# do this for all the images\n",
    "# we have the way to get top pixel imp values at the top\n",
    "\n",
    "\n",
    "\n",
    "# Get predictions\n",
    "pred = imputer(\n",
    "    x.to(device),\n",
    "    torch.ones(num_classes, imputer.num_players, device=device)\n",
    ").softmax(dim=1).cpu().data.numpy()\n",
    "\n",
    "fig, axarr = plt.subplots(num_classes, num_classes + 1, figsize=(22, 20))\n",
    "\n",
    "for row in range(num_classes):\n",
    "    # Image\n",
    "    classes = ['Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "    mean = np.array([0.4914, 0.4822, 0.4465])[:, np.newaxis, np.newaxis]\n",
    "    std = np.array([0.2023, 0.1994, 0.2010])[:, np.newaxis, np.newaxis]\n",
    "    im = x[row].numpy() * std + mean\n",
    "    im = im.transpose(1, 2, 0).astype(float)\n",
    "    im = np.clip(im, a_min=0, a_max=1)\n",
    "    axarr[row, 0].imshow(im, vmin=0, vmax=1)\n",
    "    axarr[row, 0].set_xticks([])\n",
    "    axarr[row, 0].set_yticks([])\n",
    "    axarr[row, 0].set_ylabel('{}'.format(classes[y[row]]), fontsize=14)\n",
    "    \n",
    "    # Explanations\n",
    "    m = np.abs(values[row]).max()\n",
    "    for col in range(num_classes):\n",
    "        axarr[row, col + 1].imshow(values[row, col], cmap='seismic', vmin=-m, vmax=m)\n",
    "        axarr[row, col + 1].set_xticks([])\n",
    "        axarr[row, col + 1].set_yticks([])\n",
    "        if col == y[row]:\n",
    "            axarr[row, col + 1].set_xlabel('{:.2f}'.format(pred[row, col]), fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            axarr[row, col + 1].set_xlabel('{:.2f}'.format(pred[row, col]), fontsize=12)\n",
    "        \n",
    "        # Class labels\n",
    "        if row == 0:\n",
    "            axarr[row, col + 1].set_title('{}'.format(classes[y[col]]), fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chinese-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "num_shadow = 3\n",
    "train_set = dsets.CIFAR10('../', train=True, download=True, transform=transform_train)\n",
    "# random_indices = np.random.default_rng(seed=None).permutation(len(train_set))\n",
    "random_indices = torch.randperm(len(train_set))\n",
    "selected_i = random_indices[:30000]\n",
    "n_selected_i = random_indices[30000:]\n",
    "shadow_set = torch.utils.data.Subset(train_set, selected_i)\n",
    "target_set = torch.utils.data.Subset(train_set, n_selected_i)\n",
    "\n",
    "random_indices = torch.randperm(len(shadow_set))\n",
    "first_i = random_indices[:10000]\n",
    "second_i = random_indices[10000:20000]\n",
    "third_i = random_indices[20000:]\n",
    "shadow_set1 = torch.utils.data.Subset(shadow_set, first_i)\n",
    "shadow_set2 = torch.utils.data.Subset(shadow_set, second_i)\n",
    "shadow_set3 = torch.utils.data.Subset(shadow_set, third_i)\n",
    "\n",
    "# Set up explainer model\n",
    "explainer1 = UNet(n_classes=10, num_down=2, num_up=1, num_convs=3).to(device)\n",
    "explainer2 = UNet(n_classes=10, num_down=2, num_up=1, num_convs=3).to(device)\n",
    "explainer3 = UNet(n_classes=10, num_down=2, num_up=1, num_convs=3).to(device)\n",
    "\n",
    "# Set up FastSHAP object\n",
    "fastshap_shadow1 = FastSHAP(explainer1, imputer, link=nn.LogSoftmax(dim=1))\n",
    "fastshap_shadow2 = FastSHAP(explainer2, imputer, link=nn.LogSoftmax(dim=1))\n",
    "fastshap_shadow3 = FastSHAP(explainer3, imputer, link=nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Set up datasets\n",
    "# the train and val set are just the CIFAR dataset\n",
    "fastshap_train1 = DatasetInputOnly(shadow_set1)\n",
    "fastshap_train2 = DatasetInputOnly(shadow_set2)\n",
    "fastshap_train3 = DatasetInputOnly(shadow_set3)\n",
    "fastshap_val = DatasetInputOnly(val_set)\n",
    "\n",
    "# Train\n",
    "fastshap_shadow1.train(\n",
    "    fastshap_train,\n",
    "    fastshap_val,\n",
    "    batch_size=128,\n",
    "    num_samples=2,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=1e-2,\n",
    "    validation_samples=1,\n",
    "    lookback=10,\n",
    "    bar=True,\n",
    "    verbose=True)\n",
    "\n",
    "fastshap_shadow2.train(\n",
    "    fastshap_train,\n",
    "    fastshap_val,\n",
    "    batch_size=128,\n",
    "    num_samples=2,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=1e-2,\n",
    "    validation_samples=1,\n",
    "    lookback=10,\n",
    "    bar=True,\n",
    "    verbose=True)\n",
    "\n",
    "fastshap_shadow3.train(\n",
    "    fastshap_train,\n",
    "    fastshap_val,\n",
    "    batch_size=128,\n",
    "    num_samples=2,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=1e-2,\n",
    "    validation_samples=1,\n",
    "    lookback=10,\n",
    "    bar=True,\n",
    "    verbose=True)\n",
    "\n",
    "# Save explainer\n",
    "explainer1.cpu()\n",
    "torch.save(explainer1, './ckpt/cifar missingness explainer1.pt')\n",
    "explainer1.to(device)\n",
    "\n",
    "explainer2.cpu()\n",
    "torch.save(explainer2, './ckpt/cifar missingness explainer2.pt')\n",
    "explainer2.to(device)\n",
    "\n",
    "explainer3.cpu()\n",
    "torch.save(explainer3, './ckpt/cifar missingness explainer3.pt')\n",
    "explainer3.to(device)\n",
    "\n",
    "# for i in range(num_shadow):\n",
    "#     # Set up explainer model\n",
    "#     explainer = UNet(n_classes=10, num_down=2, num_up=1, num_convs=3).to(device)\n",
    "\n",
    "#     # Set up FastSHAP object\n",
    "#     fastshap_shadow = FastSHAP(explainer, imputer, link=nn.LogSoftmax(dim=1))\n",
    "\n",
    "#     # Set up datasets\n",
    "#     # the train and val set are just the CIFAR dataset\n",
    "#     fastshap_train = DatasetInputOnly(train_set)\n",
    "#     fastshap_val = DatasetInputOnly(val_set)\n",
    "\n",
    "#     # Train\n",
    "#     fastshap.train(\n",
    "#         fastshap_train,\n",
    "#         fastshap_val,\n",
    "#         batch_size=128,\n",
    "#         num_samples=2,\n",
    "#         max_epochs=200,\n",
    "#         eff_lambda=1e-2,\n",
    "#         validation_samples=1,\n",
    "#         lookback=10,\n",
    "#         bar=True,\n",
    "#         verbose=True)\n",
    "    \n",
    "#     # Save explainer\n",
    "#     explainer.cpu()\n",
    "#     torch.save(explainer, 'cifar missingness explainer.pt')\n",
    "#     explainer.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
